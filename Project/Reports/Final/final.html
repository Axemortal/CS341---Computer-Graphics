<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="generator" content="pandoc">
    <meta name="description" content="">

    <title>Final Project Report CS-341 2025</title>

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="css/bootstrap.min.css">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link href="ie10-viewport-bug-workaround.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/dashboard.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <style type="text/css">code{white-space: pre;}</style>
    <style type="text/css">.sidebar ul{padding-left: 10px;}</style>
    <link rel="stylesheet" href="css/cg_report.css" />
  </head>

  <body>

    <div class="container-fluid">
      <div class="row">
        <div id="sidebar" class="col-sm-3 col-md-2 sidebar">
          <!--<ul class="nav nav-sidebar">
            <li class="active"><a href="#">Overview <span class="sr-only">(current)</span></a></li>
          </ul>-->
          <ul>
          <li><a
          href="#cyberpunk-city-a-dynamically-evolving-urban-landscape"
          id="toc-cyberpunk-city-a-dynamically-evolving-urban-landscape">Cyberpunk
          City: A Dynamically Evolving Urban Landscape</a>
          <ul>
          <li><a href="#abstract" id="toc-abstract">Abstract</a></li>
          <li><a href="#overview" id="toc-overview">Overview</a></li>
          <li><a href="#feature-validation"
          id="toc-feature-validation">Feature validation</a>
          <ul>
          <li><a href="#wave-function-collapse-wfc"
          id="toc-wave-function-collapse-wfc">Wave Function Collapse
          (WFC)</a></li>
          <li><a
          href="#dynamic-billboard-texture-generation-with-noise-and-bloom-effects"
          id="toc-dynamic-billboard-texture-generation-with-noise-and-bloom-effects">Dynamic
          billboard texture generation with noise and bloom
          effects</a></li>
          <li><a href="#screen-space-reflections-ssr"
          id="toc-screen-space-reflections-ssr">Screen-Space Reflections
          (SSR)</a></li>
          </ul></li>
          <li><a href="#discussion" id="toc-discussion">Discussion</a>
          <ul>
          <li><a href="#additional-components"
          id="toc-additional-components">Additional Components</a></li>
          <li><a href="#failed-experiments"
          id="toc-failed-experiments">Failed Experiments</a></li>
          <li><a href="#challenges"
          id="toc-challenges">Challenges</a></li>
          </ul></li>
          <li><a href="#contributions"
          id="toc-contributions">Contributions</a></li>
          <li><a href="#references"
          id="toc-references">References</a></li>
          </ul></li>
          </ul>
        </div>
        <div class="col-sm-9 col-sm-offset-3 col-md-10 col-md-offset-2 main">
        
<h1 id="cyberpunk-city-a-dynamically-evolving-urban-landscape">Cyberpunk
City: A Dynamically Evolving Urban Landscape</h1>
<div
style="display: flex; justify-content: space-around; align-items: center;">
<video src="videos/Final Result.mp4" height="300px" autoplay loop>
</video>
</div>
<figcaption style="text-align: center;">
A short teaser video, gif, or image showing an overview of the final
result.
</figcaption>
<h2 id="abstract">Abstract</h2>
<p>This project presents an immersive, ever-evolving cyberpunk city. Key
features include stylized 3D buildings via Wave Function Collapse (WFC),
realistic water reflections using Screen-Space Reflections (SSR), and
animated billboards with dynamic textures and bloom effects. These
components combine to create a vibrant, self-evolving urban landscape
that draws users into a futuristic cyberpunk world.</p>
<p><i> <strong>NOTE</strong>: While the WFC-based building generation
runs smoothly across systems, we recommend using a Mac (e.g., MacBook
Air with Apple Silicon) for testing the full project. On Nvidia-equipped
laptops like the Swift X, applying procedural textures may cause driver
instability or GPU overload. This issue does not affect standard WFC
generation but may impact performance during procedural texture
rendering. Other GPU-equipped Windows laptops have not been tested.
</i></p>
<h2 id="overview">Overview</h2>
<div
style="display: flex; justify-content: space-around; align-items: center;">
<div>
<p><img src="images/Overview1.png" height="210px" style="vertical-align: middle;"></p>
</div>
<div>
<p><img src="images/Overview2.png" height="210px" style="vertical-align: middle;"></video></p>
</div>
</div>
<figcaption style="text-align: center;">
Snippets of our Final Project Scene
</figcaption>
<p>Our project presents a procedurally generated cyberpunk city powered
by WebGL and GLSL shaders. At its core is a custom implementation of the
<strong>Wave Function Collapse (WFC)</strong> algorithm, adapted to
generate large-scale, constraint-satisfying 3D city layouts arranged in
concentric circular rings. These structures are rendered using efficient
instanced meshes to reduce draw calls, while distance-based visibility
culling ensures real-time performance remains smooth. To enhance the
atmosphere, we developed a suite of <strong>animated procedural
textures</strong> (Worley, Zippy, and Square noise patterns) used to
simulate neon billboards, flickering lights, and urban facades with
dynamic energy.</p>
<p>In addition to procedural generation, one of the visual cornerstones
of the project is our <strong>screen-space reflection (SSR)
system</strong>. SSR simulates real-time planar reflections by ray
marching in screen space, allowing reflective surfaces like water to
dynamically mirror parts of the scene without the overhead of full
environment mapping. This significantly boosts visual realism,
especially in a cityscape filled with glowing lights and vibrant
textures. We later extended our procedural noise system beyond
billboards, applying it directly to some building textures as well. The
result is a city that not only evolves in structure but also in motion
and light, alive with flickers, glows, and reflections that respond
organically to camera movement and time.</p>
<h2 id="feature-validation">Feature validation</h2>
<table>
<caption>
Feature Summary
</caption>
<thead>
<tr>
<th>
Feature
</th>
<th>
Adapted Points
</th>
<th>
Status
</th>
</tr>
</thead>
<!-- <td style="background-color: #cce5ff;">Missing</td> -->
<!-- <td style="background-color: #e8ebca;">Partially Completed</td> -->
<tbody>
<tr>
<td>
Wave Function Collapse (WFC)
</td>
<td>
15
</td>
<td style="background-color: #d4edda;">
Completed
</td>
</tr>
<tr>
<td>
Runtime-evolving bloom effects on billboards
</td>
<td>
5
</td>
<td style="background-color: #d4edda;">
Completed
</td>
</tr>
<tr>
<td>
Dynamic billboard texture generation with noise
</td>
<td>
10
</td>
<td style="background-color: #d4edda;">
Completed
</td>
</tr>
<tr>
<td>
Screen-Space Reflections (SSR)
</td>
<td>
20
</td>
<td style="background-color: #d4edda;">
Completed
</td>
</tr>
</tbody>
</table>
<h3 id="wave-function-collapse-wfc">Wave Function Collapse (WFC)</h3>
<h4 id="implementation">Implementation</h4>
<p>The Wave Function Collapse (WFC) solver presented here is a fully
asynchronous, three-dimensional procedural generation system implemented
designed to generate diverse, constraint-satisfying city layouts in real
time within a WebGL environment. Our primary goals were modularity (to
ensure new tiles and rules can be added via JSON without touching core
code) and performance, targeting sub-second generation on modern
hardware. To validate cross-platform consistency, we measured Largest
Contentful Paint (LCP) and per-frame interaction latencies on both an
RTX 4080–equipped Swift X 14 laptop and an M1 MacBook Air; the Mac’s
timings deviated by less than 20% from the RTX 4080.</p>
Our approach is as follows:
<div
style="display: flex; justify-content: center; gap: 20px; align-items: center;">
<p><img src="images/wfc_assets.png" height="300px" alt="WFC Assets"></p>
</div>
<p style="text-align: center;">
<em>A comparison of the 3D assets used for procedural city generation:
city_block1.obj (left), city_block2.obj (top-right), and city_block3.obj
(bottom-right)</em>
</p>
<ol type="1">
<li><p><strong>Asset Preparation</strong>: The modular city blocks were
designed in Blender (<a href="#references">design inspired by Youtube
video</a>) and exported as separate <code>.obj</code> files, with
careful attention paid to origin alignment and attachment compatibility.
For <code>city_block2</code>, we introduced an external plane,
<code>city_block4.obj</code>, as a secondary model to serve as a
billboard surface. While <code>city_block2</code> provides the main
building mass, <code>city_block4</code>is positioned flush against its
front face. Both were exported separately but positioned with precise
relative offsets, allowing us to instance them together in-scene while
applying dynamic billboard shaders (e.g., Worley or Zippy) to the plane
only. This approach gave us fine-grained control over animated textures
without modifying the building geometry.</p>
<p>To ensure correct placement during Wave Function Collapse,
<code>city_block2</code>’s rules.json entry defines both front and back
as “outside”, ensuring these exposed billboard faces remain
unobstructed. The other faces are marked “connectable” to allow seamless
tiling with adjacent blocks. This design decision helped maximize
visibility of animated billboards in the final city layout while
maintaining structural coherence. Similar rules were applied to
<code>city_block1</code>, which features a rooftop chimney aligned to
always face up via “top”: “outside”. For <code>city_block3</code>, we
ensured faces with portruding parts face the outside.</p></li>
<li><p><strong>Rule Loading &amp; Variant Preparation</strong>: We begin
by fetching a <code>rules.json</code> file that defines each tile’s
model, face-type identifiers, allowed rotations, and a global
compatibility map. For each tile entry, we generate up to four rotated
“variants” by computing a quaternion (<code>quatFromAxisAngle</code>)
and permuting the tile’s <code>faces</code> via
<code>rotateFaces()</code>. By baking face and rotation data into each
variant upfront, the grid solver avoids on-the-fly transformations and
simplifies both constraint checks and instanced rendering.</p></li>
<li><p><strong>Grid Initialization &amp; Constraint
Propagation</strong>: The world is represented as a 3D array
<code>grid[x][y][z]</code> of cells, each holding
<code>{ collapsed: false, options: Variant[] }</code>. We repeatedly
execute a <code>while (changed)</code> loop over all uncollapsed cells:
for each candidate variant, we check its six cardinal faces against
neighbors by looking up <code>compatibility[currentFace]</code> and
ensuring at least one neighbor option has the matching opposite face.
Any failing variant is pruned, and the loop continues until no more
removals occur.</p></li>
<li><p><strong>Entropy-Driven Collapse</strong>: After convergence, we
identify all uncollapsed cells with the minimum option count (&gt;1)—the
“lowest entropy” cells—select one at random, and collapse it by drawing
a weighted random choice from its <code>options</code> (weights are
given by our <code>BLOCK_WEIGHTS</code> map). We then propagate
constraints again. This cycle of propagate → collapse → propagate
repeats until every cell is collapsed or a deadlock is
detected.</p></li>
<li><p><strong>Concentric-Ring Layout &amp; Instancing</strong>: Rather
than placing tiles in a dense 3D block, we flatten each collapsed grid
into a tile list and distribute them in three concentric circles around
the origin: each tile is placed at
(<code>cos θ × radius, sin θ × radius, z</code>). This layout emphasizes
the central area and cuts GPU overdraw. Identical mesh references are
grouped into <code>scene.instancedObjects</code>, reducing draw calls by
over 90%. Distance-based culling in
<code>updateInstancedObjectsVisibility()</code> further limits per-frame
instance counts to under 20% of total.</p></li>
</ol>
<h4 id="validation">Validation</h4>
<p><strong>Performance Profiling</strong>: On the RTX 4080 Swift X 14,
the Largest Contentful Paint (generation + assembly) clocks in at ~0.32
s, with the full-city layout (including mesh prep and texture setup)
completing in ~0.66 s. Per-frame interactions (camera motion and
culling) consistently range from 230 ms to 326 ms. On an M2 MacBook Air
(8-core, 16GB RAM, 512GB SSD), these metrics remained within 20% of the
RTX results, demonstrating robust performance across high-end and
integrated GPUs.</p>
<p><strong>Results</strong>:</p>
<div
style="display: flex; justify-content: center; gap: 20px; align-items: center;">
<p><img src="images/wfc_validation_1.jpg" height="300px" alt="WFC Validation 1">
<img src="images/wfc_validation_2.jpg" width = "300px" height="300px" alt="WFC Validation 2"></p>
</div>
<p style="text-align: center;">
<em>WFC-Generated Building Variant 1 (8x9x10)</em>
</p>
<div
style="display: flex; justify-content: center; gap: 20px; align-items: center;">
<p><img src="images/wfc_validation_3_1.png" height="300px" alt="WFC Validation 1">
<img src="images/wfc_validation_3_2.png" width = "300px" height="300px" alt="WFC Validation 2"></p>
</div>
<div
style="display: flex; justify-content: center; gap: 20px; align-items: center;">
<p><img src="images/wfc_validation_3_3.png" height="300px" alt="WFC Validation 1">
<img src="images/wfc_validation_3_4.png" width = "250px" height="300px" alt="WFC Validation 2"></p>
</div>
<p style="text-align: center;">
<em>WFC-Generated Building Variant 2 (12x10x10)</em>
</p>
<h3
id="dynamic-billboard-texture-generation-with-noise-and-bloom-effects">Dynamic
billboard texture generation with noise and bloom effects</h3>
<h4 id="implementation-1">Implementation</h4>
<p>Our approach to implementing procedural textures is as follows:</p>
<ol type="1">
<li><p><strong>Worley Noise</strong>: This procedural texture is
generated using a fragment shader that produces animated Worley noise (a
cellular noise pattern) and enhances it with glitchy color distortions
and dynamic visual effects. The shader first calculates Worley noise by
scattering pseudo-random feature points in a grid and computing the
minimum squared distance from each fragment to these points. Multiple
layers of this noise—scaled and offset differently—are composed and
non-linearly combined using nested sqrt functions to add complexity and
richness to the pattern.</p>
<p>To stylize the output, the shader applies UV distortions (based on
sine waves and time) and blends two base colors (a pink and a blue)
based on the Worley value. Additionally, glitchy RGB bands and fast
vertical stripes modulate the final look, creating a techno-organic,
vibrant visual suitable for cyberpunk elements like animated billboards
or energy fields. This texture is rendered to a framebuffer using a
full-screen quad and a WebGL pipeline set up in the WorleyShaderRenderer
class, allowing it to be dynamically updated each frame using time,
scale, and camera offsets.</p></li>
<li><p><strong>Zippy</strong>: This procedural texture generates
animated glimmering flow lines, resembling headlights moving along a
dark road or illuminated windows flickering across a cityscape, using a
2D Worley noise function. The fragment shader transforms screen
coordinates into UV space and applies a vertical time-based offset to
simulate movement, evoking the feel of continuous traffic flow. The
Worley noise function places pseudo-random feature points within a grid
and calculates the minimum distance from each fragment to these points,
creating a cellular pattern. This distance is inverted and sharpened
using smoothstep to isolate small, bright spots that represent
glimmering lights.</p>
<p>A flickering effect is introduced using a deterministic pseudo-random
function modulated by time, ensuring that only some of the lights blink
on and off to create a dynamic feel. Although the shader includes logic
to interpolate between cool whites and warm reds based on position and
time, in practice the texture primarily displays bright white lights.
This is due to the dominance of the higher-luminance white values and
the masking applied by the flicker logic, which tends to wash out the
red tones. The result is a visually engaging, animated texture ideal for
simulating vehicle lights or ambient illumination in a
cyberpunk environment.</p></li>
<li><p><strong>Square</strong>: This procedural texture is generated by
layering multiple grids of flickering neon-like blocks at different
scales, creating a vibrant, dynamic pattern. Each grid divides the UV
space into cells of varying sizes—from large blocks to tiny flicks—and
uses a hash function to randomly determine which cells light up and
their color hues. By animating the hash inputs over time, the shader
produces a lively flickering effect that simulates neon signs or LED
displays.</p>
<p>Additionally, subtle vertical drifting and horizontal scanline
shimmer are applied to mimic the imperfect movement and refresh
artifacts of real electronic panels. Finally, the colors are boosted
with a glow effect and gamma correction to enhance brightness and
contrast, resulting in a richly animated, colorful texture that can
evoke the look of a bustling cyberpunk cityscape or
futuristic neon signage.</p></li>
<li><p><strong>Water</strong>: This fragment shader generates a dynamic,
deep blue water-like procedural texture using layered and warped fractal
noise. It starts by computing smooth noise at multiple scales to create
fractal noise, then distorts it further with time-varying offsets to
simulate fluid movement. The shader compares closely spaced noise
samples to create sharp bump-like highlights and shadows, enhancing the
illusion of small waves or ripples on the water surface. These bumps are
intensified nonlinearly to add contrast and subtle detail to the
texture.</p>
<p>The final color blends a deep blue base with soft bluish highlights
influenced by the noise bumps, giving a natural variation to the water’s
surface. A slight gamma correction (square root) is applied to adjust
brightness and contrast, making the texture visually richer and more
realistic. Overall, this shader creates an organic, gently shifting
water pattern that can be used for effects like lakes, pools, or sci-fi
liquid surfaces in a procedural graphics context.</p></li>
<li><p><strong>Performance Optimisation</strong>: Our
<strong>ProceduralTextureGenerator</strong> class manages the creation
and updating of multiple procedural textures using different shader
renderers such as Worley, Zippy, Square, and Water. It sets up
full-screen quad meshes and framebuffers (FBOs) for rendering each
procedural texture offscreen. Each texture is rendered separately,
optionally enhanced with a bloom effect, and the results are stored as
GPU resources for use elsewhere in the application. The class supports
dynamic resizing of textures based on the viewer’s zoom level, allowing
for level-of-detail (LOD) adjustments that balance visual quality and
performance.</p>
<p>Performance is optimized through several strategies: first, dynamic
resolution scaling reduces the texture size when the viewer is zoomed
out, cutting GPU load without sacrificing visible detail; second,
framebuffer ping-ponging allows bloom effects to be applied efficiently
by alternating between two buffers without costly memory allocations;
finally, rendering is skipped entirely if the texture would be too small
to be noticeable (when zoomed far out). These measures together keep the
procedural texture updates smooth and performant, especially important
for real-time or interactive scenes.</p></li>
<li><p><strong>Bloom Effect</strong>: Our BloomShaderRenderer implements
a classic bloom post-processing effect using multiple shader passes with
regl. It starts with a bright-pass filter that isolates the brightest
parts of the input texture by thresholding pixel luminance, effectively
extracting glow-worthy highlights. Then, it applies a two-pass Gaussian
blur—first horizontally, then vertically—using weighted texture samples
to create a smooth, soft glow around those bright areas. Finally, the
blurred bloom texture is combined additively with the original input to
produce the final image, enhancing the perceived brightness and creating
the characteristic bloom glow effect.</p>
<p>The implementation uses multiple framebuffers to ping-pong
intermediate results efficiently without reallocating resources each
frame. The blur weights and kernel size are carefully chosen for a
balanced blur that is visually pleasing but not too expensive. This
modular design with separate shader stages for bright-pass, blur, and
combine allows flexible reuse and tuning, making it a performant and
visually effective bloom solution for real-time rendering in
WebGL applications.</p></li>
</ol>
<h4 id="validation-1">Validation</h4>
<p><strong>Results</strong>:</p>
<div
style="display: flex; justify-content: center; gap: 20px; align-items: center;">
<p><img src="videos/worley.gif" height="300px" alt="Worley Texture">
<img src="videos/worley_no_bloom.gif" height="300px" alt="Worley Texture"></p>
</div>
<p style="text-align: center;">
<em>Validated Procedural Textures for Worley Noise With (Left) and
Without Bloom (Right)</em>
</p>
<div
style="display: flex; justify-content: center; gap: 0px; align-items: center;">
<p><img src="videos/square.gif" height="300px" alt="Square Texture">
<img src="videos/zippy.gif" height="300px" alt="Zippy Texture"></p>
</div>
<p style="text-align: center;">
<em>Validated Procedural Textures for Square and Zippy Noises</em>
</p>
<div
style="display: flex; justify-content: center; gap: 0px; align-items: center;">
<p><img src="videos/water.gif" height="300px" alt="Water Texture"></p>
</div>
<p style="text-align: center;">
<em>Validated Procedural Textures for Water Noise</em>
</p>
<h3 id="screen-space-reflections-ssr">Screen-Space Reflections
(SSR)</h3>
<h4 id="implementation-2">Implementation</h4>
<p>For a more in-depth explanation, please refer to the <a
href="#references">SSR Guide by David Lettier</a>, which served as the
primary inspiration for this feature’s implementation.</p>
<p>Our approach follows these main steps:</p>
<ol type="1">
<li><strong>Render the base image</strong> without any reflections or
shadows into a texture.</li>
<li><strong>Generate a reflection map</strong> to determine which points
in the base texture should be sampled for reflections. This involves:
<ol type="a">
<li>Calculating the position, normal, and reflection vector for each
point on a reflective surface.</li>
<li>Using the position and reflection vector to determine the start and
end points for ray marching.</li>
<li>Converting these coordinates into screen space for performance
efficiency, as ray marching in screen space reduces redundant
sampling.</li>
<li>Performing ray marching, with a sampling rate defined by a
resolution factor.</li>
<li>Recording hits by checking whether any scene geometry is
sufficiently close to the sampled points along the reflection ray.</li>
<li>Refining the hit point to accurately determine where to sample the
reflection color.</li>
<li>Applying fade factors based on edge proximity, distance from the
reflection plane, and other conditions to create a more natural
reflection effect.</li>
</ol></li>
<li><strong>Sample reflection colors</strong> from the base texture
using the UV indices generated from the ray-marched hits. We also fill
in gaps between sample points to reduce visual noise in the
reflection.</li>
<li><strong>Apply a blur</strong> to the sampled reflection colors and
store the result in a separate texture.</li>
<li><strong>Combine everything</strong> to produce the final reflection
output by blending the base image with both the original and blurred
reflection textures, using weighting factors for a smooth and realistic
result.</li>
</ol>
<h4 id="validation-2">Validation</h4>
<strong>Results</strong>:
<div
style="display: flex; justify-content: space-around; align-items: center;">
<div>
<p><img src="images/ssr_reflection_uv.png" height="210px" style="vertical-align: middle;"></p>
</div>
</div>
<figcaption style="text-align: center;">
Visualised UV coordinates sampled for SSR
</figcaption>
<div
style="display: flex; justify-content: space-around; align-items: center;">
<div>
<p><img src="images/ssr_validation_1.png" height="210px" style="vertical-align: middle;"></p>
</div>
<div>
<p><img src="images/ssr_validation_2.png" height="210px" style="vertical-align: middle;"></p>
</div>
</div>
<figcaption style="text-align: center;">
Validating SSR implementation on sample scene
</figcaption>
<div
style="display: flex; justify-content: space-around; align-items: center;">
<div>
<p><img src="images/ssr_validation_final.png" height="210px" style="vertical-align: middle;"></p>
</div>
</div>
<figcaption style="text-align: center;">
Final integration of SSR into the complete project scene
</figcaption>
<h2 id="discussion">Discussion</h2>
<h3 id="additional-components">Additional Components</h3>
<p><strong>UI Controls</strong>: Sliders and dropdowns let users tweak
central/small grid dimensions, toggle small-grid rings, and reassign
per-block materials (Worley, Zippy, Square) on the fly. <strong>Scene
Reloading</strong>: Scene Reloading: reloadScene and reloadCityScene
clear and reinitialize objects, ensuring that parameter changes apply
immediately without full page reloads.</p>
<h3 id="failed-experiments">Failed Experiments</h3>
<p>Initially, we attempted to dynamically attach planes at runtime to
the front face of <code>city_block2</code> for billboard rendering. The
goal was to procedurally generate these billboard surfaces based on
exposed tile faces post-WFC. However, this approach ran into consistent
spatial alignment issues: the planes would either clip into the block,
float too far forward, or misalign due to varying tile rotations and
origin inconsistencies.</p>
<p>After multiple failed attempts at calculating reliable attachment
offsets and normals dynamically, we switched strategies. Instead, we
pre-authored the plane (<code>city_block4.obj</code>) directly in
Blender and exported it with precise positioning relative to
<code>city_block2</code>. This guaranteed consistent alignment and
simplified runtime placement, allowing us to treat the billboard as a
second instanced mesh while preserving visual coherence.</p>
<h3 id="challenges">Challenges</h3>
<ol type="1">
<li><p>Constraint Design &amp; Modularity Integrating Wave Function
Collapse (WFC) with procedural textures required careful architectural
planning to ensure modularity without compromising visual coherence.
Crafting rules.json involved encoding spatial constraints—like forcing
chimneys or billboard mounts to face outward—while avoiding
overconstraining the generation space. Balancing logic and aesthetics
was especially tricky when defining how tiles could rotate and connect
across different layers and rings of the city.</p></li>
<li><p>Runtime Texture Integration Another major challenge was coupling
the WFC-generated layout with our real-time procedural texture system.
Textures such as Worley, Zippy, and Square had to be rendered to
framebuffers and dynamically applied to billboard surfaces without
breaking the instancing system used for performance. Since multiple tile
variants could share the same geometry but differ in texture depending
on face exposure, we needed precise control over material mappings,
ensuring that billboard planes consistently displayed the correct
animated shader output per frame.</p></li>
<li><p>Codebase Complexity &amp; Shader Refactor At the project’s start,
navigating the inherited codebase was a significant barrier. To
streamline development, we initiated a full codebase refactor: enforcing
standardized naming conventions, extracting reusable components, and
unifying shader handling logic. For instance, we consolidated multiple
vertex shaders into a single generic pass_through.vert.glsl, reducing
redundancy and simplifying pipeline management across shader
renderers.</p></li>
<li><p>Performance Bottlenecks As we began combining WFC logic, dynamic
instancing, procedural shaders, and screen-space effects (like SSR and
bloom), performance became a growing concern—especially on lower-end or
driver-sensitive systems (such as RTX 4080). Excessive draw calls,
redundant framebuffer switches, and unnecessary texture updates were
identified as bottlenecks. We responded with several optimizations:
grouping identical mesh-material pairs into instanced batches, skipping
texture rendering when off-screen, and using framebuffer ping-ponging to
avoid memory churn. These changes brought down our total frame times and
ensured smooth interactions on integrated GPUs like the M2 MacBook
Air.</p></li>
</ol>
<h2 id="contributions">Contributions</h2>
<table>
<caption>
Worked hours
</caption>
<thead>
<tr>
<th>
Name
</th>
<th>
Week 1
</th>
<th>
Week 2
</th>
<th>
Week 3
</th>
<th>
Week 4
</th>
<th>
Week 5
</th>
<th>
Week 6
</th>
<th>
Week 7
</th>
<th>
Total
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Eunice Lee (402359)
</td>
<td>
2
</td>
<td style="background-color: #f0f0f0;">
5
</td>
<td>
4
</td>
<td>
4
</td>
<td>
6
</td>
<td>
6
</td>
<td>
8
</td>
<td>
35
</td>
</tr>
<tr>
<td>
Howell Chan (402360)
</td>
<td>
2
</td>
<td style="background-color: #f0f0f0;">
5
</td>
<td>
6
</td>
<td>
6
</td>
<td>
6
</td>
<td>
6
</td>
<td>
6
</td>
<td>
37
</td>
</tr>
<tr>
<td>
Yifan Wu (402391)
</td>
<td>
0
</td>
<td style="background-color: #f0f0f0;">
20
</td>
<td>
4
</td>
<td>
4
</td>
<td>
4
</td>
<td>
2
</td>
<td>
2
</td>
<td>
36
</td>
</tr>
</tbody>
</table>
<table>
<caption>
Individual contributions
</caption>
<thead>
<tr>
<th>
Name
</th>
<th>
Contribution
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Eunice Lee (402359)
</td>
<td>
1/3
</td>
</tr>
<tr>
<td>
Howell Chan (402360)
</td>
<td>
1/3
</td>
</tr>
<tr>
<td>
Yifan Wu (402391)
</td>
<td>
1/3
</td>
</tr>
</tbody>
</table>
<h4 id="comments">Comments</h4>
<p>For this project:</p>
<ul>
<li>Howell implemented dynamic building generation using <strong>Wave
Function Collapse</strong> and also worked on integrating the final
scene.</li>
<li>Eunice focused on generating dynamic <strong>procedural
textures</strong> using noise, enhanced with the <strong>bloom
effect</strong>, and contributed to integrating the final scene.</li>
<li>Yifan refactored the initial codebase to ensure a consistent and
unified implementation, and developed the <strong>Screen-Space
Reflection Feature</strong>.</li>
</ul>
<h2 id="references">References</h2>
<ul>
<li><a
href="https://www.youtube.com/watch?v=wruwfND2B9A&amp;t=631s">Creating
Sci-Fi Cyberpunk Buildings in Blender</a></li>
<li><a
href="https://github.com/lettier/3d-game-shaders-for-beginners/blob/master/sections/screen-space-reflection.md">SSR
Guide by David Lettier</a></li>
<li><a
href="https://github.com/oddmax/unity-wave-function-collapse-3d">Wave
Function Collapse Algorithm from GitHub</a></li>
<li><a href="https://www.shadertoy.com/view/Xl2XWz">Warped 2D Noise from
ShaderToy</a></li>
<li><a href="https://www.shadertoy.com/view/llS3RK">Worley Noise from
ShaderToy</a></li>
<li><a href="https://www.shadertoy.com/view/XXyGzh">Zippy Noise from
ShaderToy</a></li>
</ul>
        </div>
      </div>
    </div>
    
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="js/jquery.min.js"></script>
		<script src="js/bootstrap.min.js"></script>
    <script>
        //document.getElementById('sidebar').getElementsByTagName('ul')[0].className += "nav nav-sidebar";
        
        /* ajust the height when click the toc
           the code is from https://github.com/twbs/bootstrap/issues/1768
        */
        var shiftWindow = function() { scrollBy(0, -50) };
        window.addEventListener("hashchange", shiftWindow);
        function load() { if (window.location.hash) shiftWindow(); }
        
        /*add Bootstrap styles to tables*/
        var tables = document.getElementsByTagName("table");
        for(var i = 0; i < tables.length; ++i){
            tables[i].className += "table table-bordered table-hover";
        }
    </script>
  </body>
</html>
